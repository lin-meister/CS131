My intuition when solving this problem was that in an ideal scenario, we could
map every symbol generated by a rule to every symbol in the fragment we are 
trying to match. Of course, the question arises: what if the current symbol
is a nonterminal, or there aren't enough symbols in the rule to map to each
symbol in the fragment? In that case, we see if we can delegate the task 
of matching one or more symbols in the fragment to the children of the current
symbol we are on. Once it is found in the children, we return it back up to the
initial level of recursion through a curried function that we passed down, 
acting in a role similar to that of a custom-defined internal acceptor which
we use to "decide" the found derivation internally. During this process, we
employ recursion to match the style of functional programming, and in fact
we need to use two functions that recursively call each other; one for
attempting to match a fragment to a rule, and in the process tries to match 
a fragment from a symbol's children, thus calling the other attempting to match 
a fragment from a start symbol, which then needs to match the fragment to a 
rule that the start symbol generates...
We repeat this process for every rule until we run out of rules or symbols in 
the fragment, in which case we return None, or we find a match the acceptor 
accepts, in which case we return whatever the acceptor returns. This can be 
classified as a "top-down" approach, as it traverses the grammar rules 
starting at the start symbol, trying each rule in order, generating children 
if necessary, and backtracking on failed rules, repeating this process until 
finding a match. I ultimately chose this approach due to its simplicity and
how intuitive it seemed. 
While devising a solution to this problem, I considered a 
number of approaches. One such approach was a bottom-up approach, which 
proposes that instead of starting from the first rule and searching for the
rules in order to find a match, we build up from each terminal symbol and
substitute it for its "parent" nonterminal symbols, until we reach a point
where we find a rule that contains exactly those nonterminal symbols. For
example, using the awkish_grammar as our grammar, ["3"; "+"; "4"] could be
bubbled up to [N Num; N Binop; N Num], which could then be bubbled up to 
[N Term; N Binop; N Term], etc., all the way until we reach the top level rule
in the derivation, [N Term; N Binop; N Expr]. Although this intuitively made 
sense and possibly provided some optimizations over the top-down approach 
which would have to examine every rule, I ended up rejecting this approach.
The primary reason was that this approach had a number of steps that seems
rather natural for humans, but not in programmatic instructions that would
be interpreted by a computer. For example, in the above example, we notice 
that after bubbling up "+" to N Binop, we stop finding further parents,
while we repeat the bubbling up process for the other symbols. As humans,
we can glance at the grammar and know that this is correct as Binop is 
at the "top-level" rule already, whereas the other symbols are not there yet
and thus must be bubbled. However, I found this differentiation to be too
drawn out to implement in a program, so I opted for the possibly slower but
simpler top-down approach, though the bottom-up approach may be a thought
process that one may consider in future alternative implementations for this
kind of parser.
Another thought process I followed was processing each rule according to its
classification: whether the number of symbols it generated was greater than,
equal to, or less than the number of symbols in the fragment we wanted to 
match. If the number was greater, then skip it because no matter what, we 
won't be able to "fill in" each symbol in the rule with a symbol from the
fragment. If the number was equal, then we could map each symbol from the 
fragment to every symbol from the rule, or one of its children. However,
I was stumped when thinking about the case when the number was less than.
I eventually came up with a "greedy" solution such that we would try to
map the first prefix that matches in the fragment to the first symbol,
then the next, etc. For example, with the fragment ["$"; "9"; "+"; "1"] one
could see that we could try finding a match for "$" to N Lvalue, which 
would obviously fail, so we try the next prefix, "$9", which succeeds. 
Later, though, a TA pointed out to me that this was essentially the same 
approach as the actual final approach I took, and that this process of 
assigning the first matching prefix of a fragment to the symbols of a rule
from left to right could be applied to all rules, so in a way this intuition
became the inspiration for my final approach.
In terms of weaknesses, this approach to the parser assumes one particular
feature for the grammar: that all rules are left-associative, i.e. the left-
most rules will not be recursive, only the right-most. Since our approach
evaluates and expands symbols in a rule from left to right, it would end up
in an infinite loop of repeating such a process, unless we introduce some 
sort of limit to the depths it may go down. 